{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c6f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch._logging.set_logs(graph_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45a3543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] TRACED GRAPH\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  ===== __compiled_fn_1_98bfb258_f1f8_4138_953c_7fe6f2b01a2e =====\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]  /Users/Deependu/notes/red-arrow/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_x_ = L_x_\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         l_y_ = L_y_\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:2 in foo, code: a = torch.sin(x)\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:3 in foo, code: b = torch.cos(y)\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:4 in foo, code: return a + b\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         return (add,)\n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code]         \n",
      "V1110 19:55:34.814000 22813 torch/_dynamo/output_graph.py:1983] [0/0] [__graph_code] \n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] TRACED GRAPH\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  ===== __compiled_fn_3_5951c991_6d5b_4a58_9298_1c2b3476e41b =====\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]  /Users/Deependu/notes/red-arrow/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_x_ = L_x_\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         l_y_ = L_y_\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:13 in opt_foo2, code: a = torch.sin(x)\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:14 in opt_foo2, code: b = torch.cos(y)\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1190750881.py:15 in opt_foo2, code: return a + b\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         return (add,)\n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code]         \n",
      "V1110 19:55:47.095000 22813 torch/_dynamo/output_graph.py:1983] [1/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3670e-01,  1.7276e+00, -3.7221e-01],\n",
      "        [-1.3269e-03, -1.0509e+00, -2.0892e-02],\n",
      "        [ 1.4534e+00,  8.0737e-01,  7.5619e-01]])\n",
      "tensor([[-0.7475, -0.0232, -1.8530],\n",
      "        [ 1.9620,  1.1253,  1.5489],\n",
      "        [ 1.5670,  0.1449, -0.0686]])\n"
     ]
    }
   ],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "opt_foo1 = torch.compile(foo)\n",
    "print(opt_foo1(torch.randn(3, 3), torch.randn(3, 3)))\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "print(opt_foo2(torch.randn(3, 3), torch.randn(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3e22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] TRACED GRAPH\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  ===== __compiled_fn_5_920067cf_9c67_454c_b5fb_96677de8051f =====\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]  /Users/Deependu/notes/red-arrow/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_x_ = L_x_\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         l_y_ = L_y_\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/2199486826.py:2 in inner, code: return torch.sin(x)\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/2199486826.py:8 in outer, code: b = torch.cos(y)\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/2199486826.py:9 in outer, code: return a + b\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         return (add,)\n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code]         \n",
      "V1110 19:57:45.459000 22813 torch/_dynamo/output_graph.py:1983] [2/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1975,  1.4264,  0.5204],\n",
      "        [ 1.1221, -0.9894,  1.2334],\n",
      "        [ 0.5513,  1.3970,  1.1348]])\n"
     ]
    }
   ],
   "source": [
    "def inner(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def outer(x, y):\n",
    "    a = inner(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "print(outer(torch.randn(3, 3), torch.randn(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0261218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] TRACED GRAPH\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  ===== __compiled_fn_7_fa869ad0_7769_4148_a003_061f53e18e7e =====\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]  /Users/Deependu/notes/red-arrow/.venv/lib/python3.12/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]     def forward(self, L_self_modules_lin_parameters_weight_: \"f32[3, 3][3, 1]cpu\", L_self_modules_lin_parameters_bias_: \"f32[3][1]cpu\", L_x_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_self_modules_lin_parameters_weight_ = L_self_modules_lin_parameters_weight_\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_self_modules_lin_parameters_bias_ = L_self_modules_lin_parameters_bias_\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         l_x_ = L_x_\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]          # File: /var/folders/62/sqk699ld69v13ny7hdx8n4980000gn/T/ipykernel_22813/1084626883.py:7 in forward, code: return torch.nn.functional.relu(self.lin(x))\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         linear: \"f32[3, 3][3, 1]cpu\" = torch._C._nn.linear(l_x_, l_self_modules_lin_parameters_weight_, l_self_modules_lin_parameters_bias_);  l_x_ = l_self_modules_lin_parameters_weight_ = l_self_modules_lin_parameters_bias_ = None\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         relu: \"f32[3, 3][3, 1]cpu\" = torch.nn.functional.relu(linear);  linear = None\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         return (relu,)\n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code]         \n",
      "V1110 19:59:08.770000 22813 torch/_dynamo/output_graph.py:1983] [3/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.6000, 0.3552],\n",
      "        [1.0293, 0.2921, 0.0000],\n",
      "        [0.3256, 0.0052, 0.0000]], grad_fn=<CompiledFunctionBackward>)\n",
      "tensor([[0.4790, 0.7246, 0.0000],\n",
      "        [1.5001, 0.2692, 0.0000],\n",
      "        [0.5898, 0.4999, 0.0000]], grad_fn=<CompiledFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.nn.functional.relu(self.lin(x))\n",
    "\n",
    "\n",
    "mod1 = MyModule()\n",
    "mod1.compile()\n",
    "print(mod1(torch.randn(3, 3)))\n",
    "\n",
    "mod2 = MyModule()\n",
    "mod2 = torch.compile(mod2)\n",
    "print(mod2(torch.randn(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0936714",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m     torch.cuda.synchronize()\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result, start.elapsed_time(end) / \u001b[32m1024\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m inp = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcompile:\u001b[39m\u001b[33m\"\u001b[39m, timed(\u001b[38;5;28;01mlambda\u001b[39;00m: opt_foo3(inp))[\u001b[32m1\u001b[39m])\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33meager:\u001b[39m\u001b[33m\"\u001b[39m, timed(\u001b[38;5;28;01mlambda\u001b[39;00m: foo3(inp))[\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notes/red-arrow/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "def foo3(x):\n",
    "    y = x + 1\n",
    "    z = torch.nn.functional.relu(y)\n",
    "    u = z * 2\n",
    "    return u\n",
    "\n",
    "\n",
    "opt_foo3 = torch.compile(foo3)\n",
    "\n",
    "\n",
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1024\n",
    "\n",
    "\n",
    "inp = torch.randn(4096, 4096).cuda()\n",
    "print(\"compile:\", timed(lambda: opt_foo3(inp))[1])\n",
    "print(\"eager:\", timed(lambda: foo3(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad52c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red-arrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
